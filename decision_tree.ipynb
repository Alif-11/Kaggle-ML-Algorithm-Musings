{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70e93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79fb6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "['unacc' 'acc' 'vgood' 'good']\n",
      "BuyingPrice        vhigh\n",
      "MaintenanceCost    vhigh\n",
      "NumberOfDoors          2\n",
      "NumberOfPersons        2\n",
      "LugBoot            small\n",
      "Safety               low\n",
      "Decision           unacc\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "csvfile = \"/Users/alifabdullah/Collaboration/Kaggle-ML-Algorithm-Musings/datasets/car_evaluation.csv\"\n",
    "csv_in_panda_form = pd.read_csv(csvfile)\n",
    "target_column = \"Decision\"\n",
    "feature_columns = [feature_header for feature_header in csv_in_panda_form.columns.drop(target_column)]\n",
    "\n",
    "#print(csv_in_panda_form)\n",
    "#print(feature_columns)\n",
    "\n",
    "#for row in csv_in_panda_form.iterrows():\n",
    "#  print(row[1][\"Outcome\"])\n",
    "\n",
    "print(len(csv_in_panda_form[csv_in_panda_form[\"NumberOfDoors\"] == '2']))\n",
    "print((csv_in_panda_form[\"Decision\"].unique()))\n",
    "print(csv_in_panda_form.iloc[0])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branch:\n",
    "  \"\"\"\n",
    "  This class represents a branch from a Decision tree.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.value = None\n",
    "    self.next_node : 'DecisionTreeNode' = None\n",
    "\n",
    "  def change_value(self, value):\n",
    "    self.value = value\n",
    "\n",
    "  def change_next_node(self, next_node: 'DecisionTreeNode'):\n",
    "    self.next_node = next_node\n",
    "\n",
    "class DecisionTreeNode:\n",
    "  \"\"\"\n",
    "  This class represents the nodes that will make up my decision tree.\n",
    "  There are two types of nodes. Branching nodes - whose children are either\n",
    "  more branching nodes or leaf nodes - and leaf nodes - where, upon reaching these\n",
    "  nodes, you end up with a label for the test instance.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.list_of_branches : List[Branch] = [] # Branch Node only\n",
    "    self.label = None # Leaf Node only\n",
    "    self.feature_name = None # Branch Node only\n",
    "    self.decision = None # Leaf Node only\n",
    "  \n",
    "  # Creates a Branch Node\n",
    "  def add_branch(self, branch: Branch):\n",
    "    self.list_of_branches.append(branch)\n",
    "  \n",
    "  # Creates a Leaf Node\n",
    "  def change_label(self, label):\n",
    "    self.label = label\n",
    "  \n",
    "  # Changes the feature name of a Branch Node\n",
    "  def assign_feature_name(self, feature_name):\n",
    "    # Ensure immutability for feature name once we assign it\n",
    "    assert self.feature_name is None, \"Cannot reassign feature name.\"\n",
    "\n",
    "    self.feature_name = feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f34b92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature split: 65\n",
      "BuyingPrice: 62\n",
      "MaintenanceCost: 49\n",
      "NumberOfDoors: 61\n",
      "NumberOfPersons: 63\n",
      "LugBoot: 48\n",
      "Safety: 30\n",
      "All features before split: ['BuyingPrice', 'MaintenanceCost', 'NumberOfDoors', 'NumberOfPersons', 'LugBoot', 'Safety']\n",
      "Features left: ['BuyingPrice', 'MaintenanceCost', 'NumberOfDoors', 'NumberOfPersons', 'LugBoot']\n",
      "Before feature split: 30\n",
      "BuyingPrice: 30\n",
      "MaintenanceCost: 30\n",
      "NumberOfDoors: 30\n",
      "NumberOfPersons: 30\n",
      "LugBoot: 9\n",
      "All features before split: ['BuyingPrice', 'MaintenanceCost', 'NumberOfDoors', 'NumberOfPersons', 'LugBoot']\n",
      "Features left: ['BuyingPrice', 'MaintenanceCost', 'NumberOfDoors', 'NumberOfPersons']\n",
      "Before feature split: 9\n",
      "BuyingPrice: 9\n",
      "MaintenanceCost: 9\n",
      "NumberOfDoors: 3\n",
      "NumberOfPersons: 9\n",
      "All features before split: ['BuyingPrice', 'MaintenanceCost', 'NumberOfDoors', 'NumberOfPersons']\n",
      "Features left: ['BuyingPrice', 'MaintenanceCost', 'NumberOfPersons']\n",
      "Before feature split: 3\n",
      "BuyingPrice: 3\n",
      "MaintenanceCost: 3\n",
      "NumberOfPersons: 0\n",
      "All features before split: ['BuyingPrice', 'MaintenanceCost', 'NumberOfPersons']\n",
      "Features left: ['BuyingPrice', 'MaintenanceCost']\n",
      "huh None\n",
      "what Safety\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what LugBoot\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what NumberOfDoors\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what NumberOfPersons\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what None\n",
      "huh None\n",
      "what None\n"
     ]
    }
   ],
   "source": [
    "def _decision_tree_maker(dataframe : pd.DataFrame, list_of_labels, features_to_consider, target_column):\n",
    "  head_node = DecisionTreeNode()\n",
    "\n",
    "  # Base Case 1: If our dataset is empty or the error is 0, meaning all labels are the same\n",
    "  if len(dataframe) == 0:\n",
    "    head_node.change_label(list_of_labels[0]) # There is no data to make a label with, so just pick one.\n",
    "    return head_node\n",
    "  \n",
    "  # Base Case 2: The minority label has instance count 0, meaning all labels are the same in this dataset\n",
    "  if _dataset_error_calculator(dataframe, list_of_labels, target_column) == 0:\n",
    "\n",
    "    head_node.change_label(dataframe[target_column])\n",
    "    return head_node\n",
    "  \n",
    "  # Induction step\n",
    "  else:\n",
    "    biggest_error_diff = 0\n",
    "    feature_with_biggest_error_diff = None\n",
    "\n",
    "    # Compare error before any feature split with each feature split's error:\n",
    "    error_before_split = _dataset_error_calculator(dataframe, list_of_labels, target_column)\n",
    "    print(f\"Before feature split: {error_before_split}\")\n",
    "\n",
    "    # Loop over every feature to get its error on the dataframe\n",
    "    for feature in features_to_consider:\n",
    "      feature_error = _dataset_error_calculator(dataframe, list_of_labels, target_column, feature)\n",
    "      print(f\"{feature}: {feature_error}\")\n",
    "\n",
    "      # Find the feature split that causes the biggest error difference from before to after the split\n",
    "      if error_before_split - feature_error > biggest_error_diff:\n",
    "        biggest_error_diff = error_before_split - feature_error\n",
    "        feature_with_biggest_error_diff = feature\n",
    "    \n",
    "    # Assign the current node to have the feature that causes the biggest error \n",
    "    # difference from before to after the split\n",
    "    head_node.assign_feature_name(feature_with_biggest_error_diff)\n",
    "    features_left = [feature_left for feature_left in features_to_consider if feature_left != feature_with_biggest_error_diff]\n",
    "    print(f\"All features before split: {features_to_consider}\")\n",
    "    list_of_unique_value_datasets, list_of_unique_values = _dataset_splitter_using_feature(dataframe, feature_with_biggest_error_diff)\n",
    "    print(f\"Features left: {features_left}\")\n",
    "    for unique_value_dataset, unique_value in zip(list_of_unique_value_datasets, list_of_unique_values):\n",
    "\n",
    "      # Fixing how we add branches to our decision tree implementation.\n",
    "      current_branch = Branch()\n",
    "      current_branch.change_value(unique_value)\n",
    "      next_decision_tree_node = _decision_tree_maker(unique_value_dataset, list_of_labels, features_left, target_column)\n",
    "      current_branch.change_next_node(next_decision_tree_node)\n",
    "\n",
    "      head_node.add_branch(current_branch)\n",
    "    return head_node\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# DEPRECATING THIS FUNCTION\n",
    "def _decision_tree_split_decider(dataframe : pd.DataFrame, list_of_labels, target_column):\n",
    "  \"\"\"\n",
    "  Takes in a Pandas dataframe, goes through every feature, figures out which \n",
    "  one gives the greatest error difference before and after the particular feature,\n",
    "  chooses that to split the data, and repeats the process for the remaining\n",
    "  features.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get all features beside target column\n",
    "  all_features = dataframe.drop(columns=[target_column]).columns.to_list()\n",
    "\n",
    "  # All non terminating nodes of the tree (that are at the end of value branches\n",
    "  # a previously chosen feature).\n",
    "  frontier = []\n",
    "\n",
    "  # Repeat the decision tree construction process until all features have been looked at\n",
    "  while len(all_features) > 0:\n",
    "\n",
    "    biggest_error_diff = 0\n",
    "    feature_with_biggest_error_diff = None\n",
    "\n",
    "    # Compare error before any feature split with each feature split's error:\n",
    "    error_before_split = _dataset_error_calculator(dataframe, list_of_labels, target_column)\n",
    "    #print(f\"Before feature split: {error_before_split}\")\n",
    "\n",
    "    # Loop over every feature to get its error on the dataframe\n",
    "    for feature in all_features:\n",
    "      feature_error = _dataset_error_calculator(dataframe, list_of_labels, target_column, feature)\n",
    "      #print(f\"{feature}: {feature_error}\")\n",
    "\n",
    "      # Find the feature split that causes the biggest error difference from before to after the split\n",
    "      if error_before_split - feature_error > biggest_error_diff:\n",
    "        biggest_error_diff = error_before_split - feature_error\n",
    "        feature_with_biggest_error_diff = feature\n",
    "    \n",
    "    current_tree_node = DecisionTreeNode()\n",
    "    unique_values_of_the_current_biggest_feature = dataframe[feature_with_biggest_error_diff].unique()\n",
    "    print(f\"Feature with biggest error diff: {feature_with_biggest_error_diff}\")\n",
    "    print(f\"Unique Values of the feature with biggest error diff: {unique_values_of_the_current_biggest_feature}\")\n",
    "\n",
    "    # Create our tree head, and give it the feature with the biggest error difference\n",
    "    # from before the split to after the split\n",
    "    current_tree_node.assign_feature_name(feature_with_biggest_error_diff)\n",
    "\n",
    "    for unique_value_of_the_current_biggest_feature in unique_values_of_the_current_biggest_feature:\n",
    "      print(f\"Individual unique values: {unique_value_of_the_current_biggest_feature}\")\n",
    "      branch_of_the_current_tree_node = Branch()\n",
    "      branch_of_the_current_tree_node.change_value(unique_value_of_the_current_biggest_feature)\n",
    "      current_tree_node.add_branch(branch_of_the_current_tree_node)\n",
    "      print(f\"Dataset splits for the feature with greatest error diff: {_dataset_splitter_using_feature(dataframe, feature_with_biggest_error_diff)}\")\n",
    "      \n",
    "      # Get sub datasets whose values correspond to the current chosen value, and\n",
    "      # the feature splitting.\n",
    "    print(f\"Current tree node: {current_tree_node}\")\n",
    "    print(f\"Branches of the current tree node: {current_tree_node.list_of_branches}\")\n",
    "    break\n",
    "\n",
    "def _dataset_splitter_using_feature(dataframe, feature) -> Tuple[List[Any], List[Any]]:\n",
    "  \"\"\"\n",
    "  Takes in a feature, and then returns a list of dataset splits, one for each unique\n",
    "  value of the feature, where each split has the same value for the column 'feature'\n",
    "  \"\"\"\n",
    "  list_of_dataset_splits = []\n",
    "  unique_values = dataframe[feature].unique()\n",
    "  for unique_value in unique_values:\n",
    "    list_of_dataset_splits.append(dataframe[dataframe[feature]==unique_value])\n",
    "  return list_of_dataset_splits, unique_values\n",
    "\n",
    "def _dataset_error_calculator(dataframe, list_of_labels, target_column, feature=None):\n",
    "  \"\"\"\n",
    "  If you pass in a feature, get the error difference between the dataset before \n",
    "  the feature split, and after the feature split.\n",
    "  \"\"\"\n",
    "  if feature is not None:\n",
    "    unique_feature_values = dataframe[feature].unique()\n",
    "    error_sum = 0\n",
    "    \n",
    "    # Go through every unique value of the chosen feature\n",
    "    for feature_value in unique_feature_values:\n",
    "\n",
    "      # Get all rows where the current feature value is present for the feature column.\n",
    "      # Aggregate the sum of the errors in error_sum\n",
    "      current_df = dataframe[dataframe[feature] == feature_value]\n",
    "      current_df_error, label_to_count_mapping_dictionary_current_df = _dataset_consistency_metrics(current_df, list_of_labels, target_column)\n",
    "      error_sum += current_df_error\n",
    "\n",
    "    return error_sum\n",
    "  else:\n",
    "\n",
    "    # After looking over every label, return the label that has the least amount of\n",
    "    # instances associated with it.\n",
    "    error, label_to_count_mapping_dictionary = _dataset_consistency_metrics(dataframe, list_of_labels, target_column)\n",
    "    return error\n",
    "    \n",
    "\n",
    "def _dataset_consistency_metrics(dataframe, list_of_labels, target_column):\n",
    "  \"\"\"\n",
    "  Tells you the counts of instances, in a dataset, corresponding to labels, as \n",
    "  well as the error of the dataset, where the error is calculated as the number\n",
    "  of dataset instances corresponding to the label with the least instances.\n",
    "\n",
    "  Args:\n",
    "    dataframe - A Pandas DataFrame, representing our dataset\n",
    "    list_of_labels - List of labels that represents all labels that could be assigned (replaced by self.list_of_labels going forward)\n",
    "    target_column: The name of the column we are trying to predict (replaced by self.target_column going forward)\n",
    "  \n",
    "  Returns:\n",
    "    error - The error, as defined above\n",
    "    label_counts - A dictionary mapping between labels and their respective counts\n",
    "  \"\"\"\n",
    "  label_count_mapping_dict = dict()\n",
    "  for key in list_of_labels:\n",
    "    label_count_mapping_dict[key] = 0\n",
    "  \n",
    "  for row in dataframe.iterrows():\n",
    "    label_count_mapping_dict[row[1][target_column]] += 1 \n",
    "  \n",
    "  error = float(\"inf\")\n",
    "  for key in list_of_labels:\n",
    "    if label_count_mapping_dict[key] < error:\n",
    "      error = label_count_mapping_dict[key]\n",
    "  return error, label_count_mapping_dict\n",
    "\n",
    "# print(_dataset_error_calculator(csv_in_panda_form, ['unacc','acc','vgood','good'], \"Decision\", None))\n",
    "# print(_dataset_error_calculator(csv_in_panda_form, ['unacc','acc','vgood','good'],\"Decision\", \"NumberOfDoors\"))\n",
    "\n",
    "# print(_decision_tree_split_decider(csv_in_panda_form, ['unacc','acc','vgood','good'], \"Decision\"))\n",
    "\n",
    "all_features = csv_in_panda_form.drop(columns=[\"Decision\"]).columns.to_list()\n",
    "constructed_decision_tree = _decision_tree_maker(csv_in_panda_form, ['unacc','acc','vgood','good'], all_features, \"Decision\")\n",
    "\n",
    "def _print_all_tree_parts(tree_node : DecisionTreeNode):\n",
    "  print(\"huh\",tree_node.label)\n",
    "  print(\"what\",tree_node.feature_name)\n",
    "  for branch in tree_node.list_of_branches:\n",
    "    #print(branch.value)\n",
    "    _print_all_tree_parts(branch.next_node)\n",
    "\n",
    "\n",
    "_print_all_tree_parts(constructed_decision_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
